{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DsD-LMKT7XMt"
      },
      "source": [
        "<center>\n",
        "<h1>\n",
        "<h1>APM 53674: ALTeGraD</h1>\n",
        "<h2>Lab Session 2: Pretraining and Supervised Finetuning</h2>\n",
        "<h4>Lecture: Prof. Michalis Vazirgiannis<br>\n",
        "Lab: Dr. Hadi Abdine and Yang Zhang</h4>\n",
        "<h5>Tuesday, October 07, 2025</h5>\n",
        "<br>\n",
        "</center>\n",
        "\n",
        "<hr style=\"border:10px solid gray\"> </hr>\n",
        "<p style=\"text-align: justify;\">\n",
        "This handout includes theoretical introductions, <font color='blue'>coding tasks</font> and <font color='red'>questions</font>. Before the deadline, you should submit <a href='https://forms.gle/9dyaes6dimfvyjwq6' target=\"_blank\">here</a> a <B>.ipynb</B> file named <b>Lastname_Firstname.ipynb</b> containing your notebook (with the gaps filled and your answers to the questions). Your answers should be well constructed and well justified. They should not repeat the question or generalities in the handout. When relevant, you are welcome to include figures, equations and tables derived from your own computations, theoretical proofs or qualitative explanations. One submission is required for each student. The deadline for this lab is <b>October 12\n",
        ", 2025 11:59 PM</b>. No extension will be granted. Late policy is as follows: ]0, 24] hours late ‚Üí -5 pts; ]24, 48] hours late ‚Üí -10 pts; > 48 hours late ‚Üí not graded (zero).\n",
        "</p>\n",
        "<hr style=\"border:5px solid gray\"> </hr>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8Z2srf-7VTu"
      },
      "source": [
        "## <b>Instruction Finetuning</b>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tzv7XNDM7Tim"
      },
      "source": [
        "\n",
        "\n",
        "In this lab, you will learn about fine-tuning large language models (LLMs) for specific tasks.\n",
        "\n",
        "Instruction fine-tuning enables models to follow human instructions effectively by training on high-quality instruction-response pairs.\n",
        "\n",
        "We will implement these techniques using Python and the Hugging Face ecosystem, including transformers and datasets,  By the end of the lab, you will have hands-on experience in adapting LLMs to specific use cases and evaluating their performance.\n",
        "\n",
        "In summary, we will:\n",
        "\n",
        "* Finetune [Qwen2-0.5B](https://huggingface.co/Qwen/Qwen2-0.5B) on a question/answer dataset.\n",
        "\n",
        "* To reduce the required GPU VRAM for the finetuning, we will use [LoRA](https://www.anyscale.com/blog/fine-tuning-llms-lora-or-full-parameter-an-in-depth-analysis-with-llama-2) and [quantization](https://huggingface.co/blog/4bit-transformers-bitsandbytes) techniques.\n",
        "\n",
        "* Compare the results before and after instruction tuning.\n",
        "\n",
        "<center>\n",
        "<img src='https://onedrive.live.com/embed?resid=AE69638675180117%21292802&authkey=%21AO_qaECmI1InIyg&width=634&height=556' width=\"500\">\n",
        "\n",
        "\n",
        "LoRA: Low Rank Adapataion. Taken from LoRA original paper\n",
        "\n",
        "<img src='https://onedrive.live.com/embed?resid=AE69638675180117%21292801&authkey=%21AIBM2HNKRF7tzGo&width=1980&height=866' width=\"700\">\n",
        "\n",
        "QLoRA. Taken from QLoRA original paper\n",
        "\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdl5minU7JhQ"
      },
      "source": [
        "### <b>Finetuning Qwen2.5-0.5B using HuggingFace's Transfromers</b>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUCV4V0ONKeJ"
      },
      "source": [
        "\n",
        "In this section, we will fintune [Qwen2.5-0.5B](https://huggingface.co/Qwen/Qwen2.5-0.5B) - a powerful open-weight family of language models known for a  strong multilingual and reasoning capabilities - on a question answering dataset.\n",
        "\n",
        "Supervised Fine-Tuning (SFT) is a crucial step in adapting pre-trained language models to specific tasks or domains by training them on high-quality instruction-response pairs. We will use the Hugging Face Transformers library for working with pre-trained models, PEFT (Parameter-Efficient Fine-Tuning) to apply efficient fine-tuning techniques like LoRA, and Bitsandbytes for optimizing memory usage, enabling us to fine-tune large models on consumer hardware.\n",
        "\n",
        "A key aspect of fine-tuning conversational models is structuring prompts correctly using chat templates. A chat template defines how inputs and outputs are formatted to ensure consistency during training and inference. In our lab, we will use the following chat template:\n",
        "```\n",
        "<human>: {Question}\n",
        "<assistant>: {Answer}\n",
        "```\n",
        "\n",
        "Such formats helps the model differentiate between user inputs and assistant responses, ensuring better alignment with real-world chat applications.\n",
        "\n",
        "In this section, we will focus on completion-only fine-tuning, meaning we will train the model only on generating the assistant‚Äôs response while not learning to generate the prompt. This approach is efficient and useful when adapting a model to specific response styles or improving answer quality.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Kk-AEdr65TO"
      },
      "source": [
        "#### <b>Preparing the environment and installing libraries:<b>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xvYPeqtmLTiu",
        "outputId": "b7c7bbfe-a8e0-480e-dec5-d1e91323931e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sun Oct 12 15:57:08 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   49C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khRdXTxqy9V_",
        "outputId": "4c912b6d-0eb0-4045-e917-7e98612702ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m60.1/60.1 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m564.6/564.6 kB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -qqq bitsandbytes torch transformers peft accelerate datasets loralib einops trl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "qHHXf0xHUsx9"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "from pprint import pprint\n",
        "\n",
        "import bitsandbytes as bnb\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import transformers\n",
        "from datasets import load_dataset\n",
        "from trl import DPOConfig, DPOTrainer\n",
        "\n",
        "from peft import (\n",
        "    LoraConfig,\n",
        "    PeftConfig,\n",
        "    PeftModel,\n",
        "    get_peft_model,\n",
        "    prepare_model_for_kbit_training,\n",
        "    PeftModelForCausalLM\n",
        ")\n",
        "from transformers import (\n",
        "    AutoConfig,\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    BitsAndBytesConfig,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WzHeSpov7CCZ"
      },
      "source": [
        "#### <b>Loading the model and the tokenizer:</b>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MC-Kv8g8MSuW"
      },
      "source": [
        "\n",
        "\n",
        "In this section, we will load the Qwen model while using the BitsAndBytes library for quantization.\n",
        "\n",
        "The Bitsandbytes library is a powerful tool for optimizing large language model (LLM) training and inference by enabling 8-bit and 4-bit quantization, significantly reducing memory usage while maintaining model performance. Quantization is a technique that compresses model weights from higher precision (e.g., 16-bit or 32-bit floating point) to lower precision (8-bit or 4-bit), allowing models to run efficiently on consumer-grade GPUs. This is particularly useful for fine-tuning and deploying large models that would otherwise require substantial computational resources.\n",
        "\n",
        "In Bitsandbytes, key parameters control how quantization is applied:\n",
        "\n",
        "- **nf4 (Normalized Float 4)**: A 4-bit data type designed to better preserve model accuracy by focusing on commonly used weight ranges.\n",
        "- **bnb_4bit_compute_dtype**.\n",
        "- **bnb_4bit_quant_type**: Specifies the quantization method, commonly \"nf4\" or \"fp4\" (floating-point 4-bit).\n",
        "- **load_in_4bit=True**: Enables 4-bit quantization for efficient memory usage.\n",
        "- **load_in_8bit=True**: Enables 8-bit quantization, which offers a trade-off between efficiency and precision.\n",
        "- **bnb_4bit_use_double_quant**.\n",
        "\n",
        "Quantization works by mapping continuous weight values into a smaller discrete range, which reduces the memory footprint of the model while keeping it functionally effective. In practice, Bitsandbytes 4-bit quantization allows fine-tuning of large models on GPUs with as little as 16GB VRAM, making it an essential tool for efficient model adaptation and deployment.\n",
        "\n",
        "In our lab, we will store the model in the VRAM with 4 bits using the 'nf4' quantization method, do the computation using brain float 16 (BF16) and use double quantization.\n",
        "\n",
        "<b><h4><font color='red'>\n",
        "<hr style=\"border:10px solid red\"> </hr>\n",
        "Question 1: </b><br>\n",
        "What is computation dtype in the context of quantization (which can be specified using bnb_4bit_compute_dtype)? What is the importance of double quantization?\n",
        "<hr style=\"border:10px solid red\"> </hr>\n",
        "</font></h4>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0U4t0WAB0hJS"
      },
      "source": [
        "<b><h4><font color='green'>\n",
        "<hr style=\"border:10px solid red\"> </hr>\n",
        "Answer 1: </b><br>\n",
        "\n",
        "In quantization, the computation dtype refers to the data type  used during computations (particularly during matrix multiplication operations).\n",
        "Although weights are stored in 4 bits to reduce memory usage, they must be temporarily dequantized to a more precise format to perform computations. The bnb_4bit_compute_dtype parameters control this format.\n",
        "\n",
        "\n",
        "Double quantization is a technique that adds a second layer of quantization to already quantized weights. Indeed, the quantization scales are themselves quantized. For example, in the case of 4-bit weights, they will be quantized to 8 bits (this is not mandatory... they can be quantized to 16 or 32 bits).\n",
        "This allows for additional compression, especially for large models.\n",
        "\n",
        "\n",
        "<hr style=\"border:10px solid red\"> </hr>\n",
        "</font></h4>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqOLPM9R0qDd"
      },
      "source": [
        "<b><h4><font color='blue'>\n",
        "<hr style=\"border:10px solid blue\"> </hr>\n",
        "Task 1: </b><br>\n",
        "According to what is described earlier, fill the gap to create our BitsAndBytes configuration.\n",
        "<hr style=\"border:10px solid blue\"> </hr>\n",
        "</font></h4>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343,
          "referenced_widgets": [
            "016dc246900d4f82ac6b1d0ebeafad4d",
            "2846c5147b0644849581f420e1817772",
            "ff6fa0aee5ea4454a179f6c3c14f9fc3",
            "d2a0cf4017504bfa94c4e358fed13c66",
            "5aa873d821a843589fd502122a2ef2b7",
            "b50ee2a66fa94f42aa6e5c73c700146e",
            "18d7e30e6e86421c8947869ce8ed58e9",
            "12be7a84871e422d93e8ce9163f14bf6",
            "5fe0e3ca26094887b8e2e2a51b8609af",
            "457945646c454fb2afe0036057ea2478",
            "68eab869c607401c8617e374229d9a7c",
            "2c6b682a617e4121801716146cbcbd80",
            "21123b76fb4545729c678f1b6e0f3aa3",
            "6ff18712d3724cc6b261c4245fb535ca",
            "6a5ef989a3b04c8bba7810e2caeaa776",
            "c4964153ba2f40279af0a58a125ec649",
            "1ea233a13ae24852889b88dda54ed8cf",
            "ad03c3f15c3143429208388a757930e8",
            "55bb76f0c1864f5cb73d564caf994b57",
            "c042d32a13464def96e23b0a291ed721",
            "758eeb797856437aaca30fbe1379de5f",
            "c3d4570f0230484eba3de3f899a1e9f2",
            "e6387a5f695445a98c8995cecbf18435",
            "111721b2039b4d1a9eef2b600bd51e62",
            "00390ef4c2ae47d2a2e0aeadd243c4e8",
            "d344cf337973452aae91223f5ab2e30c",
            "07c1102d4abb49c7be8d0b71d39ae0ad",
            "e27b3439aa58443e8c26f9066deb5544",
            "d1326ca9a28a4897b6eea25fdb5ee628",
            "5529703f5e8b42829a04eafa5d7f489d",
            "26f512f281154bc2a671ca9032f62140",
            "ded8613d89d44362835bbf1e5ab2f9be",
            "44d9f880d4df42b9a8c2970ce2fbe06e",
            "7cfade15caf0410c9af8395f10d654b6",
            "79bc7c86990a47f9962106b8c1c1bf04",
            "9cda1da37406458d89b792bc7abf7c2f",
            "1b2b457922044fe095930e8970313e23",
            "e62a7e318fbb4879b37373e54f79b44e",
            "3ee5d686ed5d4e9f95aafdff3306724b",
            "7b280e3e10e54f289c127a0fcb7d6dba",
            "e903d036c0954d37b17fe1aa77bebf4b",
            "18c476442f654d46944028bcb6dea1f1",
            "eb2578e9d5504032bb798220db6934d9",
            "da62ac3e6dee4086ac6c36b0ce623e0d",
            "8de04f39f6bc432cbafa1ca3b1735719",
            "84efd3f32661479ea722cc20fd6d11c5",
            "8553b312076a40d183a410d2f66a04d4",
            "2af02b47c4454816bbe39923cb23a713",
            "81a347fd1cd34ff2931e95dcded7bab2",
            "9b26a0fbc43c415b8563a1eab3a017ee",
            "0b7886db752749c897cccaffb61a4fe5",
            "c07186353f674b6ebc6a049116163776",
            "5f8e1d2cefb144d2a50c56955a44cf0b",
            "03e11d0567f347da939219d7fbe7bd2a",
            "47de712a122541819e0fdbc8d0bab144",
            "02693d08230f40afaad5b517dcea156b",
            "5309323cac39409ab0afd7a3f21abc91",
            "c6abf84705b6472aafeadfd22241c2c8",
            "2e5d4dbf42cd4acb930fc1b2ceeb8635",
            "0d22c3713d8944369ee750181a1688a9",
            "4bbd33200f2d4f70a3c9e82c6180ce5e",
            "71e13f745b73412386ecaf77e1a3a7f4",
            "6c06338aa2824c788b7b95d94d0ed0b5",
            "8aa8f681889940c5ab78b70c43f36895",
            "ce539e8a90c143b087749213656d5c7d",
            "a7923c0a6a9e4abf8a1a3d34108f83eb",
            "a642d4cc1b004bbba23c3c607a832b0f",
            "e3455db1655d4f0c9f80bfa38955e59d",
            "69aa6e90aa0a43c080a86757c1916786",
            "0a55c25909fb4ffcba918aae23062a2e",
            "af7e08e9bed0464797c94b1355478727",
            "7652d83dfa4140479a4ab4129e746c92",
            "dbd126a69b2a495fb267e3591942cb64",
            "76c19a4b1e864f9da51923205f6a7e11",
            "f6216a395dc4485cbd4b8f3a54c84543",
            "b6bf2c7d8813479dafcfbcd6235a2eee",
            "f17bba977fb64d8887960c651cf6cde6"
          ]
        },
        "id": "X6TaXDnRVKDq",
        "outputId": "7825cb10-68df-46c9-9aab-3f373ebbf8f8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "016dc246900d4f82ac6b1d0ebeafad4d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/681 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2c6b682a617e4121801716146cbcbd80",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/988M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e6387a5f695445a98c8995cecbf18435",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/138 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7cfade15caf0410c9af8395f10d654b6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8de04f39f6bc432cbafa1ca3b1735719",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "02693d08230f40afaad5b517dcea156b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "merges.txt: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a642d4cc1b004bbba23c3c607a832b0f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "MODEL_NAME = \"Qwen/Qwen2.5-0.5B\"\n",
        "# MODEL_NAME = \"unsloth/Llama-3.2-1B\" # to go further, try llama with unsloth\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    bnb_4bit_quant_type='nf4',\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "\n",
        ")## configuration of quantization\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True,\n",
        "    quantization_config=bnb_config,\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "tokenizer.pad_token = tokenizer.eos_token"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTgKyxhJMeEP"
      },
      "source": [
        "#### <b>Configuring LoRA:</b>\n",
        "\n",
        "PEFT (Parameter-Efficient Fine-Tuning) is a library designed to fine-tune large language models (LLMs) efficiently by updating only a small subset of parameters, instead of the entire model. This significantly reduces memory consumption and computational cost, making it feasible to adapt large models on consumer GPUs. One of the most popular PEFT techniques is LoRA (Low-Rank Adaptation), which injects small trainable adapters into specific layers of the model while keeping the original weights frozen.\n",
        "\n",
        "Instead of modifying the large pre-trained weight matrices directly, **LoRA** decomposes weight updates into two smaller matrices of a lower rank. These low-rank matrices are trained, while the original model remains frozen, leading to faster training, lower memory usage, and minimal performance degradation.\n",
        "\n",
        "When applying LoRA using PEFT, several important parameters are used:\n",
        "\n",
        "- **r (Rank)**: The rank of the low-rank matrices added to the model.\n",
        "Common Practice: Values like 8, 16, or 32 are often used. Higher ranks improve model adaptability but require more memory. In our lab we will use a LoRA rank of 32.\n",
        "- **lora_alpha**: The scaling factor for LoRA updates.\n",
        "Common Practice: Set as 2 √ó rank (e.g., 16 for rank 8, 32 for rank 16) to ensure a good balance between stability and adaptation.\n",
        "- **lora_dropout**: Dropout applied to LoRA layers to prevent overfitting.\n",
        "Common Practice: 0.05‚Äì0.1 is commonly used. In our lb we will use 0.05.\n",
        "- **target_modules**: Specifies which model layers should be fine-tuned with LoRA.\n",
        "Common Practice: For transformer models like LLaMA, Qwen, and Mistral, LoRA is typically applied on all projection (MLP) layers inside the transformer block (so excluding the embedding and language modeling head layers).\n",
        "\n",
        " **Note:** set `bias` to `'none'` and do not forget to set the `task_type` to the causla language modeling task.\n",
        "\n",
        "<b><h4><font color='blue'>\n",
        "<hr style=\"border:10px solid blue\"> </hr>\n",
        "Task 2: </b><br>\n",
        "Fill the gap in the next cell to compute the number of trainable parameters in a pytorch model in order to check later the effect of using LoRA. <b>Hint:</b> trainable parameters require their grdients to be saved in the memory during training.\n",
        "<hr style=\"border:10px solid blue\"> </hr>\n",
        "</font></h4>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "LIvuxW4lVW_E"
      },
      "outputs": [],
      "source": [
        "def print_trainable_parameters(model):\n",
        "\n",
        "    \"\"\"\n",
        "    Prints the number of trainable parameters in the model.\n",
        "    \"\"\"\n",
        "    trainable_params = 0\n",
        "    all_param = 0\n",
        "    for _, param in model.named_parameters():\n",
        "        all_param += param.numel()\n",
        "        if param.requires_grad:\n",
        "            trainable_params += param.numel()\n",
        "        ## get the number of trainable parameters: trainable_params\n",
        "    print(\n",
        "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nywupL1V_Y1f"
      },
      "source": [
        "<b><h4><font color='blue'>\n",
        "<hr style=\"border:10px solid blue\"> </hr>\n",
        "Task 3: </b><br>\n",
        "According to what is described earlier, fill the gap to create your LoRA configuration then use it to define your model. <b>Hint: </b> run a cell containing only <i>model</i> to extract the target modules. <b>\n",
        "<hr style=\"border:10px solid blue\"> </hr>\n",
        "</font></h4>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duTYSKKYVamH",
        "outputId": "27436a31-4fe4-4d53-9536-6617ebe5c3f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainable params: 17596416 || all params: 332715904 || trainable%: 5.288721034507566\n"
          ]
        }
      ],
      "source": [
        "config = LoraConfig(\n",
        "    r=32,\n",
        "    lora_alpha=64,\n",
        "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type='CAUSAL_LM',\n",
        ") #Configuration of LoRA\n",
        "\n",
        "model = get_peft_model(model, config) #define the model using LoRA configs\n",
        "print_trainable_parameters(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hG1vTbsx_p5Y"
      },
      "source": [
        "<b><h4><font color='red'>\n",
        "<hr style=\"border:10px solid red\"> </hr>\n",
        "Question 2: </b><br>\n",
        "With a small language model of 0.5B parameters (Qwen2 for instance), and assuming we are using Adam optimizer along with BF16 (no quantization). Compare the size of required VRAM to train the model with and without using LoRA (with the same configuration in this lab). Please detail you answer (i.e. required VRAM for model parameters, gradients and optimizer states. <b>Note:</b> Ignore for this question the required memory for the input sequence and its activation memory.\n",
        "<hr style=\"border:10px solid red\"> </hr>\n",
        "</font></h4>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtUCDSN6_6Ah"
      },
      "source": [
        "<b><h4><font color='green'>\n",
        "<hr style=\"border:10px solid red\"> </hr>\n",
        "Answer 2: </b><br>\n",
        "\n",
        "\n",
        "The following hypotheses are considered:\n",
        "\n",
        "- Number of parameters : 0.5B\n",
        "- Training in BF16\n",
        "- Adam optimizer\n",
        "\n",
        "We have two cases :  \n",
        "\n",
        "### First without LoRA\n",
        "\n",
        "The model has $N = 5 \\times 10^8$ parameters\n",
        "For each parameter, this is the number of byte used :\n",
        "\n",
        "\n",
        "- For gradients : 2 bytes because the model is using BF16\n",
        "- Weights : 2 bytes because BF16 = 16 bits = 2 bytes\n",
        "- Optimizer states : FP32 = 8 bytes\n",
        "\n",
        "\n",
        "\n",
        "So in total there are 12 bytes per parameter. That is $5 \\times 10^{8} \\times 12 = 6*10^{9}$\n",
        "\n",
        "So without LoRa we need about 6GB of memory.\n",
        "\n",
        "### Second with LoRA üá∞\n",
        "\n",
        "With LoRA, we freeze the weights of the base model and only train small adaptation matrices.\n",
        "\n",
        "With LoRA, the number of trainable parameters is often between 0.5 and 1%. We will consider this number of parameters to be 1%.\n",
        "\n",
        "The total memory then becomes $5\\times10^{8}√ó2 + 0.01\\times5\\times10^{8}\\times12$\n",
        "\n",
        "We therefore obtain $10^{9} + 60000000 = 1060000000$ bytes\n",
        "or approximately 1GB\n",
        "\n",
        "So we can clearly see that by taking 1% of the parameters (this is the upper range normally with LoRA, we're more between 0.5 and 1) we arrive at only 1GB of VRAM compared to 6GB without LoRA.\n",
        "\n",
        "\n",
        "<hr style=\"border:10px solid red\"> </hr>\n",
        "</font></h4>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5H1bBQaSNVsr"
      },
      "source": [
        "#### <b>Test the model before finetuning:</b>\n",
        "\n",
        "A chat template defines how inputs and responses are formatted when interacting with a conversational model. It ensures consistency between training and inference, allowing the model to correctly distinguish between user queries and assistant replies. A well-structured template is essential for fine-tuning because it guides the model‚Äôs learning process, preventing confusion and improving response quality.\n",
        "\n",
        "As mentioned before, in this lab, we will use the following chat template:\n",
        "\n",
        "```\n",
        "<human>: {Question}\n",
        "<assistant>: {Answer}\n",
        "```\n",
        "\n",
        "\n",
        "<b><h4><font color='blue'>\n",
        "<hr style=\"border:10px solid blue\"> </hr>\n",
        "Task 4: </b><br>\n",
        "Fill the gap to create a simple prompt using the described chat template with the question: <i>What equipment do I need for rock climbing?</i> Then test what the model generate before finetuning.\n",
        "<hr style=\"border:10px solid blue\"> </hr>\n",
        "</font></h4>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRW7HPX6WCmI",
        "outputId": "8dd544ab-cdd1-4f65-858e-7d4192318d4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<human>:What equipment do I need for rock climbing?\n",
            "<assistant>{}\n"
          ]
        }
      ],
      "source": [
        "prompt =  \"<human>:What equipment do I need for rock climbing?\\n<assistant>{}\" #construct the promp with an empty response from the assistant\n",
        "print(prompt)\n",
        "\n",
        "generation_config = model.generation_config\n",
        "generation_config.max_new_tokens = 200\n",
        "generation_config.temperature = 0.7\n",
        "generation_config.top_p = 0.7\n",
        "generation_config.num_return_sequences = 1\n",
        "generation_config.pad_token_id = tokenizer.eos_token_id\n",
        "generation_config.eos_token_id = tokenizer.eos_token_id\n",
        "generation_config.do_sample = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DnmKXlqSWPQq",
        "outputId": "1b99f970-1967-40e3-f90e-e9a105f3b968"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<human>:What equipment do I need for rock climbing?\n",
            "<assistant>{}:You need a pair of climbing shoes, a rope, a harness, and a helmet.\n",
            "<assistant>{}:What are the most important skills to have?\n",
            "<assistant>{}:You need to be able to hold a rope, climb, and carry a load.\n",
            "<assistant>{}:What is the best way to learn rock climbing?\n",
            "<assistant>{}:You can start by learning how to climb a tree or building a wall.\n",
            "<assistant>{}:What is the best way to learn rock climbing?\n",
            "<assistant>{}:You can start by learning how to climb a tree or building a wall.\n",
            "<assistant>{}:What is the best way to learn rock climbing?\n",
            "<assistant>{}:You can start by learning how to climb a tree or building a wall.\n",
            "<assistant>{}:What is the best way to learn rock climbing?\n",
            "<assistant>{}:You can start by learning how to climb a tree or building a wall.\n",
            "<assistant>{}:\n",
            "CPU times: user 27.5 s, sys: 280 ms, total: 27.8 s\n",
            "Wall time: 36.2 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "device = \"cuda:0\"\n",
        "\n",
        "encoding = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "with torch.inference_mode():\n",
        "    outputs = model.generate(\n",
        "        input_ids=encoding.input_ids,\n",
        "        attention_mask=encoding.attention_mask,\n",
        "        generation_config=generation_config,\n",
        "    )\n",
        "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8isiEVs-eUy"
      },
      "source": [
        "\n",
        "<b><h4><font color='red'>\n",
        "<hr style=\"border:10px solid red\"> </hr>\n",
        "Question 3: </b><br>\n",
        "What is the role of 'temperature' in generation configuration? what about top_p?\n",
        "<hr style=\"border:10px solid red\"> </hr>\n",
        "</font></h4>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1LHuuWGdFCN7"
      },
      "source": [
        "<b><h4><font color='green'>\n",
        "<hr style=\"border:10px solid red\"> </hr>\n",
        "Answer 3: </b><br>\n",
        "\n",
        "The temperature parameter controls the degree of randomness in text generation. It ranges from 0 to 1.\n",
        "A low temperature (0.1) makes the model more deterministic. it almost always chooses the most likely word.\n",
        "A high temperature (0.8 or higher) makes the generation more varied and creative, as the word probabilities are more balanced and the model explores more.\n",
        "The top_p parameter filters the words that will be considered by the model. With a top_p of 0.9, the model will only consider words whose cumulative probability reaches 90%.\n",
        "\n",
        "<hr style=\"border:10px solid red\"> </hr>\n",
        "</font></h4>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbhQySqVMo2T"
      },
      "source": [
        "#### <b>Loading the question answering dataset from Hugging Face Hub:</b>\n",
        "\n",
        "For fine-tuning our model, we will use the `giuliadc/orangesum_5k` dataset, a high-quality collection of articles-summaries pairs. This dataset contains news articles written in French.\n",
        "\n",
        "Each sample in the dataset follows a structured format, typically including:\n",
        "\n",
        "- **id:** The id of the article\n",
        "- **text:** The original text of the article.\n",
        "- **reference-summary:** The summary of the article."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "2zR54r9AWQ-d",
        "outputId": "f0e11f23-568a-442d-cc80-11a22db86615"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"pd\",\n  \"rows\": 5000,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5000,\n        \"samples\": [\n          \"orangesum-1502\",\n          \"orangesum-2587\",\n          \"orangesum-2654\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5000,\n        \"samples\": [\n          \"Ce jeudi 29 septembre, apr\\u00e8s une saison riche en rebondissements, Olivia Alessandri, l'h\\u00e9ro\\u00efne de \\\"La vengeance aux yeux clairs\\\", le nouveau feuilleton \\u00e0 succ\\u00e8s de TF1, achevait sa vendetta contre la famille Chevalier. Ce d\\u00e9nouement tant attendu a rassembl\\u00e9 environ 6 millions de fid\\u00e8les. Un bilan honorable, pour une fiction dont l'on attendait beaucoup. Retour sur les raisons de ce succ\\u00e8s. La\\u00ebtitia Milot, h\\u00e9ro\\u00efne au grand coeurDifficile de dissocier le succ\\u00e8s de \\\"La vengeance aux yeux clairs\\\" de celle qui incarne la s\\u00e9rie : La\\u00ebtitia Milot. La com\\u00e9dienne, r\\u00e9v\\u00e9l\\u00e9e par son r\\u00f4le dans le soap \\\"Plus belle la vie\\\" interpr\\u00e8te avec brio une vengeresse au caract\\u00e8re bien tremp\\u00e9, \\u00e0 laquelle on s'attache tr\\u00e8s rapidement. Cela est sans doute d\\u00fb au capital sympathie de l'actrice, figure incontournable du petit \\u00e9cran, que l'on ne se lasse pas de suivre depuis ses d\\u00e9buts dans la s\\u00e9rie de France 3. Une intrigue haletanteUne femme en qu\\u00eate de repr\\u00e9sailles, un cadre paradisiaque, un triangle amoureux... Les passionn\\u00e9s de fiction t\\u00e9l\\u00e9vis\\u00e9e auront vite remarqu\\u00e9 des similitudes entre l'intrigue de \\\"La vengeance aux yeux clairs\\\" et celle de la s\\u00e9rie am\\u00e9ricaine \\\"Revenge \\\", elle aussi, entre temps diffus\\u00e9e sur TF1. Toutes deux nous invitaient \\u00e0 suivre l'odyss\\u00e9e mouvement\\u00e9e de personnages f\\u00e9minins forts, avec en prime, des cliffhangers surprenants. C'est, en effet, une recette qui marche. Les histoires de vengeance ont et auront toujours la c\\u00f4te. Comme un air de nostalgieLe point commun entre les mythiques \\\"Zodiaque \\\", \\\"Le miroir de l'eau\\\" et \\\"La vengeance aux yeux clairs\\\" ? Toutes se revendiquent de la cat\\u00e9gorie des sagas de l'\\u00e9t\\u00e9. Vous savez, ces s\\u00e9ries qui nous tiennent en haleine pendant des semaines enti\\u00e8res, et dont on attend l'\\u00e9pisode prochain avec h\\u00e2te. Et bien, \\\"La vengeance aux yeux clairs\\\" en fait dignement partie et cela explique en partie son succ\\u00e8s : on est tous accro aux sagas estivales. D'ailleurs, TF1 l'a bien compris et pr\\u00e9pare d'ores et d\\u00e9j\\u00e0 une saison 2.\",\n          \"Le Vatican a lev\\u00e9 l'immunit\\u00e9 de son repr\\u00e9sentant en France, Luigi Ventura, vis\\u00e9 par une enqu\\u00eate \\u00e0 Paris pour \\\"agressions sexuelles\\\", a annonc\\u00e9 lundi 8 juillet un porte-parole du minist\\u00e8re fran\\u00e7ais des Affaires \\u00e9trang\\u00e8res. L'affaire a \\u00e9clat\\u00e9 en f\\u00e9vrier avec la r\\u00e9v\\u00e9lation de l'ouverture de l'enqu\\u00eate. La mairie de Paris avait signal\\u00e9 au parquet qu'un jeune cadre municipal s'\\u00e9tait plaint d'attouchements r\\u00e9p\\u00e9t\\u00e9s du nonce apostolique - des \\\"mains aux fesses\\\" - lors d'une c\\u00e9r\\u00e9monie des v\\u0153ux aux autorit\\u00e9s diplomatiques en janvier. Deux autres plaignants s'\\u00e9taient ensuite manifest\\u00e9s et avaient relat\\u00e9 des faits similaires en 2018. Ces trois hommes ont \\u00e9t\\u00e9 entendus par les enqu\\u00eateurs. Une quatri\\u00e8me plainte a \\u00e9t\\u00e9 d\\u00e9pos\\u00e9e par un autre homme. D\\u00e9but avril, l'\\u00e9v\\u00eaque septuag\\u00e9naire a \\u00e9t\\u00e9 entendu par la police judiciaire parisienne \\\"\\u00e0 sa demande\\\", selon une source judiciaire. Compte tenu de ses fonctions, il b\\u00e9n\\u00e9ficiait de l'immunit\\u00e9 diplomatique et ne pouvait \\u00eatre entendu sous contrainte par les enqu\\u00eateurs. Mi-avril, le minist\\u00e8re fran\\u00e7ais des Affaires \\u00e9trang\\u00e8res a indiqu\\u00e9 avoir transmis une demande de lev\\u00e9e d'immunit\\u00e9 au Vatican. \\\"Le minist\\u00e8re de l'Europe et des Affaires \\u00e9trang\\u00e8res qui avait transmis au Saint Si\\u00e8ge la demande de lev\\u00e9e de l'immunit\\u00e9 du nonce apostolique en France pr\\u00e9sent\\u00e9e par le procureur de la R\\u00e9publique de Paris, a re\\u00e7u confirmation de la part du Saint Si\\u00e8ge de sa renonciation \\u00e0 l'immunit\\u00e9 pour la proc\\u00e9dure envisag\\u00e9e\\\", a indiqu\\u00e9 le porte-parole. La lettre du Vatican est parvenue au minist\\u00e8re \\\"en fin de semaine derni\\u00e8re\\\", a-t-il pr\\u00e9cis\\u00e9. Diplomate de carri\\u00e8re du Vatican, Mgr Ventura occupe le poste de nonce apostolique depuis 2009 \\u00e0 Paris. Il est charg\\u00e9 des relations du Saint-Si\\u00e8ge avec les autorit\\u00e9s fran\\u00e7aises d'une part et avec les \\u00e9v\\u00eaques de France d'autre part, pour lesquels il participe au processus de nomination. Cette affaire s'inscrit dans un contexte de multiples scandales sexuels touchant l'\\u00c9glise catholique. Le pape Fran\\u00e7ois a d\\u00e9voil\\u00e9 en mai une l\\u00e9gislation plus stricte obligeant pr\\u00eatres, religieux et religieuses \\u00e0 signaler \\u00e0 l'\\u00c9glise tout soup\\u00e7on d'agression sexuelle ou de harc\\u00e8lement, ainsi que la couverture de tels faits par la hi\\u00e9rarchie au sein du clerg\\u00e9.\",\n          \"Des accrochages ont oppos\\u00e9 lundi des manifestants aux forces de l'ordre \\u00e0 Toulouse lors d'une manifestation lyc\\u00e9enne, qui ont fait sept bless\\u00e9s parmi les policiers, un parmi les pompiers et 11 interpellations apr\\u00e8s des vols et d\\u00e9gradations de commerces, souligne la pr\\u00e9fecture. Environ 650 lyc\\u00e9ens venus de plusieurs \\u00e9tablissements toulousains ont converg\\u00e9 \\u00e0 la mi-journ\\u00e9e vers le centre de Toulouse, apr\\u00e8s avoir commis plusieurs d\\u00e9gradations notamment dans le quartier des Ar\\u00e8nes, a soulign\\u00e9 la police. Sur l'ensemble du d\\u00e9partement de la Haute-Garonne, \\\"environ 1.300 lyc\\u00e9ens se sont mobilis\\u00e9s\\\", a indiqu\\u00e9 dans un communiqu\\u00e9 la pr\\u00e9fecture. \\\"Les forces de s\\u00e9curit\\u00e9 et de secours ont fait l'objet de tirs de projectiles. Il a fallu faire usage de gaz lacrymog\\u00e8nes afin d'en disperser les auteurs\\\", a-t-on pr\\u00e9cis\\u00e9. Le rectorat de Toulouse a confirm\\u00e9 qu'une vingtaine de lyc\\u00e9es de l'agglom\\u00e9ration \\u00e9tait impact\\u00e9e \\u00e0 des degr\\u00e9s divers par le mouvement, soulignant que plusieurs \\u00e9tablissements avaient \\u00e9t\\u00e9 bloqu\\u00e9s par des barrages avec des poubelles et des barri\\u00e8res. Des manifestations similaires en r\\u00e9gion Occitanie Des manifestations similaires ont agit\\u00e9 plusieurs lyc\\u00e9es de la r\\u00e9gion Occitanie notamment dans le Gers et le Tarn, ont constat\\u00e9 des correspondants de l'AFP. Selon une source polici\\u00e8re, une bijouterie a \\u00e9t\\u00e9 vandalis\\u00e9e dans le centre de Toulouse mais on ignorait encore si elle avait \\u00e9t\\u00e9 pill\\u00e9e. En fin de matin\\u00e9e, le r\\u00e9seau toulousain des transports en commun Tisseo avait suspendu les deux lignes de tram, toutes les lignes de bus et une des deux lignes de m\\u00e9tro \\\"en raison de plusieurs manifestations et pour des raisons de s\\u00e9curit\\u00e9\\\", selon un communiqu\\u00e9. Sur la place du Capitole, en plein c\\u0153ur de Toulouse, o\\u00f9 ils \\u00e9taient rassembl\\u00e9s dans l'apr\\u00e8s-midi, les lyc\\u00e9ens, auxquels s'\\u00e9taient joints de nombreux autres manifestants, se sont avanc\\u00e9s mains en l'air vers les CRS en criant \\\"Macron d\\u00e9mission\\\", a constat\\u00e9 un journaliste de l'AFP. La foule a \\u00e9t\\u00e9 ensuite coup\\u00e9e par des cordons de policiers qui ont repouss\\u00e9 les manifestants \\u00e0 coups de gaz lacrymog\\u00e8ne vers les petites rues du centre historique. Des rues embrum\\u00e9es de gaz lacrymog\\u00e8nes Apr\\u00e8s avoir \\u00e9t\\u00e9 chass\\u00e9s de la place du Capitole, les lyc\\u00e9ens se sont \\u00e9parpill\\u00e9s dans les rues adjacentes, jouant au jeu du chat et de la souris avec les forces de l'ordre, dans des rues embrum\\u00e9es de gaz lacrymog\\u00e8nes. Les commer\\u00e7ants du centre ville ont d\\u00fb fermer boutique et tirer les rideaux m\\u00e9talliques \\u00e0 mesure que la situation se tendait. A la dispersion de la manifestation, des jeunes repouss\\u00e9s vers une place en travaux ont renvers\\u00e9 du mobilier de chantier, a-t-on encore constat\\u00e9. Une dizaine de personnes ont \\u00e9t\\u00e9 interpell\\u00e9es, selon la police. Parmi les policiers bless\\u00e9s, une femme a \\u00e9t\\u00e9 hospitalis\\u00e9e apr\\u00e8s avoir re\\u00e7u un projectile au niveau de la t\\u00eate, s'indignait un policier de la Bac affirmant pour son compte \\u00eatre pr\\u00e9sent \\\"sur le terrain depuis 5h du matin\\\". En milieu d'apr\\u00e8s-midi, la tension \\u00e9tait mont\\u00e9e d'un cran lorsqu'un jeune, le visage en sang, \\u00e9tait embarqu\\u00e9 sans m\\u00e9nagement sous les hu\\u00e9es de quelques \\\"gilets jaunes\\\" et des passants pr\\u00e9sents, a constat\\u00e9 l'AFP. Les lyc\\u00e9ens se sont ensuite progressivement dispers\\u00e9s.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"reference-summary\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5000,\n        \"samples\": [\n          \"L'\\u00e9pisode final de la s\\u00e9rie \\u00e9v\\u00e9nement de TF1, diffus\\u00e9 ce jeudi 29 septembre, a \\u00e9t\\u00e9 suivi par plus de 6 millions de t\\u00e9l\\u00e9spectateurs.\",\n          \"Luigi Ventura est vis\\u00e9 par les plaintes de quatre hommes. Un cadre de la mairie de Paris avait notamment d\\u00e9nonc\\u00e9 des \\\"mains aux fesses\\\" r\\u00e9p\\u00e9t\\u00e9s du nonce apostolique lors d'une c\\u00e9r\\u00e9monie de v\\u0153ux en janvier.\",\n          \"D'apr\\u00e8s la pr\\u00e9fecture, 1.300 lyc\\u00e9ens se sont mobilis\\u00e9s dans le d\\u00e9partement de la Haute-Garonne dont 650 \\u00e0 Toulouse. Sept policiers et un sapeur-pompier ont \\u00e9t\\u00e9 bless\\u00e9s par des jets de projectiles.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-3bf8bef5-9fa4-4977-bfe6-2a381221edb3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>reference-summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>orangesum-1</td>\n",
              "      <td>Emmanuel Macron s'est montr√© d√©favorable √† une...</td>\n",
              "      <td>Le pr√©sident aurait s√®chement √©cart√© l'id√©e de...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>orangesum-2</td>\n",
              "      <td>Elle a √©t√© interpell√©e mardi 16 juin sans m√©na...</td>\n",
              "      <td>Elle a √©t√© film√©e lan√ßant des projectiles sur ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>orangesum-3</td>\n",
              "      <td>La confiance des Fran√ßais √† l'√©gard des financ...</td>\n",
              "      <td>SONDAGE. Quarante six pour cent des personnes ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>orangesum-4</td>\n",
              "      <td>\"L'affaire dure. (...) Mais cette histoire ne ...</td>\n",
              "      <td>C'est un soutien de poids. L'ancienne ministre...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>orangesum-5</td>\n",
              "      <td>\"On n'a rien demand√©! On est des gens honn√™tes...</td>\n",
              "      <td>A Moissac, l'heure est √† la cueillette des pre...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4995</th>\n",
              "      <td>orangesum-4996</td>\n",
              "      <td>A Vacaville, une ville d'environ 100.000 habit...</td>\n",
              "      <td>Des milliers de personnes ont fui leurs maison...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4996</th>\n",
              "      <td>orangesum-4997</td>\n",
              "      <td>Une semaine apr√®s Dieudonn√©, c'est au tour de ...</td>\n",
              "      <td>Ce proche de Dieudonn√© ne pourra pas recr√©er d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4997</th>\n",
              "      <td>orangesum-4998</td>\n",
              "      <td>Au moins dix personnes sont mortes et une autr...</td>\n",
              "      <td>Apr√®s l'incendie qui a fait 10 morts dans la n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4998</th>\n",
              "      <td>orangesum-4999</td>\n",
              "      <td>\"Si l'on parvient √† observer une √©toile qui se...</td>\n",
              "      <td>La mission d'astronomie sino-fran√ßaise Svom, v...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4999</th>\n",
              "      <td>orangesum-5000</td>\n",
              "      <td>\"Les concentrations des principaux polluants a...</td>\n",
              "      <td>Le confinement a entra√Æn√© une forte r√©duction ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5000 rows √ó 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3bf8bef5-9fa4-4977-bfe6-2a381221edb3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3bf8bef5-9fa4-4977-bfe6-2a381221edb3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3bf8bef5-9fa4-4977-bfe6-2a381221edb3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-196a922b-2f6a-43b1-951a-880912b178ad\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-196a922b-2f6a-43b1-951a-880912b178ad')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-196a922b-2f6a-43b1-951a-880912b178ad button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                  id                                               text  \\\n",
              "0        orangesum-1  Emmanuel Macron s'est montr√© d√©favorable √† une...   \n",
              "1        orangesum-2  Elle a √©t√© interpell√©e mardi 16 juin sans m√©na...   \n",
              "2        orangesum-3  La confiance des Fran√ßais √† l'√©gard des financ...   \n",
              "3        orangesum-4  \"L'affaire dure. (...) Mais cette histoire ne ...   \n",
              "4        orangesum-5  \"On n'a rien demand√©! On est des gens honn√™tes...   \n",
              "...              ...                                                ...   \n",
              "4995  orangesum-4996  A Vacaville, une ville d'environ 100.000 habit...   \n",
              "4996  orangesum-4997  Une semaine apr√®s Dieudonn√©, c'est au tour de ...   \n",
              "4997  orangesum-4998  Au moins dix personnes sont mortes et une autr...   \n",
              "4998  orangesum-4999  \"Si l'on parvient √† observer une √©toile qui se...   \n",
              "4999  orangesum-5000  \"Les concentrations des principaux polluants a...   \n",
              "\n",
              "                                      reference-summary  \n",
              "0     Le pr√©sident aurait s√®chement √©cart√© l'id√©e de...  \n",
              "1     Elle a √©t√© film√©e lan√ßant des projectiles sur ...  \n",
              "2     SONDAGE. Quarante six pour cent des personnes ...  \n",
              "3     C'est un soutien de poids. L'ancienne ministre...  \n",
              "4     A Moissac, l'heure est √† la cueillette des pre...  \n",
              "...                                                 ...  \n",
              "4995  Des milliers de personnes ont fui leurs maison...  \n",
              "4996  Ce proche de Dieudonn√© ne pourra pas recr√©er d...  \n",
              "4997  Apr√®s l'incendie qui a fait 10 morts dans la n...  \n",
              "4998  La mission d'astronomie sino-fran√ßaise Svom, v...  \n",
              "4999  Le confinement a entra√Æn√© une forte r√©duction ...  \n",
              "\n",
              "[5000 rows x 3 columns]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = load_dataset(\"giuliadc/orangesum_5k\")\n",
        "pd.DataFrame(data[\"train\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9oSZX9UcNBsu"
      },
      "source": [
        "#### <b>Preparing the finetuning data:</b>\n",
        "\n",
        "Before fine-tuning, we need to properly format the dataset to align with our chat template and ensure compatibility with the Hugging Face Trainer. Our first step is structuring the data using the already defined format.\n",
        "\n",
        "Once the dataset is structured correctly, we must prepare it for the Hugging Face Trainer, which requires the following key components:\n",
        "\n",
        "- **`input_ids`:** Tokenized input, including both the instruction and response.\n",
        "- **`attention_mask`:** Identifies which tokens should be attended to (1) and which should be ignored (0).\n",
        "- **`labels`:** Defines the target output during training.\n",
        "\n",
        "Both `input_ids` and `attention_mask`can be found in the output of the tokenizer. By default, if `labels` is not explicitly provided in our input, the model is trained to generate everything in input_ids, meaning it learns to reproduce both the instruction and the response (in this case `labels` will be a clone of `input_ids` created automatically by the trainer). However, since we are performing completion-only fine-tuning (where the model learns only to generate responses while ignoring the instruction), we must modify the labels.\n",
        "\n",
        "To achieve completion-only fine-tuning, we replace **all prompt tokens** (instruction and chat template markers like `<human>:)` with `-100`. This ensures that the model is only trained to predict the response, as tokens marked `-100` are ignored by the loss function.\n",
        "\n",
        "\n",
        "<b><h4><font color='blue'>\n",
        "<hr style=\"border:10px solid blue\"> </hr>\n",
        "Task 4: </b><br>\n",
        "Fill the gaps to: (1) transform the data into prompts using the defined chat template. (2) tokenize the data and prepare the labels to ensure that the training will be done only on generating the responses.\n",
        "<hr style=\"border:10px solid blue\"> </hr>\n",
        "</font></h4>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "4905e59d4778472aad052fc927c48586",
            "6ce2a19a0eea455883971b4c6b5d368f",
            "763350cc8eb94be8a9e04e2a44af888c",
            "54d88cb95cf541c6b64dd69c5acc8c89",
            "d359bb864887449b93f383ceebe5712c",
            "27b9e0408202451b9fa953b98f37fc19",
            "d3a374ce74264bd29ce4305394f510c3",
            "096cebe373e5443f88adb19ac1917a96",
            "e9fd2d50cbbf4240b6a3e4663ae62098",
            "c09a590b7a1949628e715b7b6ee9e82e",
            "dedf8165fcf04241aa0b2e776b85f890"
          ]
        },
        "id": "cQiJpF41WZEc",
        "outputId": "0d1cef5d-f60b-4b62-bd98-782f1700cbc6"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4905e59d4778472aad052fc927c48586",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def generate_prompt(data_point):\n",
        "\n",
        "    return f\"<human>: R√©sumez l‚Äôarticle suivant :\\n{data_point['text']}\\n<assistant>: {data_point['reference-summary']}\"##  transform the data into prompts of the format: \"<human>: R√©sumez l‚Äôarticle suivant:\\n{article}?\\n <assistant>: {summary}\"\n",
        "\n",
        "def generate_and_tokenize_prompt(data_point):\n",
        "    full_prompt = generate_prompt(data_point)+tokenizer.eos_token # eos token is important here or the model will not learn how to stop.\n",
        "    tokenized_full_prompt = tokenizer(full_prompt, return_tensors='pt')\n",
        "    if tokenized_full_prompt.input_ids.shape[1] > 2000:\n",
        "        return None\n",
        "    labels = tokenized_full_prompt.input_ids.clone()  ##  create the labels first by cloning input_ids\n",
        "\n",
        "    prompt = full_prompt[:full_prompt.find(\"<assistant>\")] + \"<assistant>:\"\n",
        "    end_prompt_idx = len(tokenizer(prompt, return_tensors='pt').input_ids[0])  ##  get the index of the '<assistant>:' (or the equivalent token) in order to replace all but response tokens with -100\n",
        "\n",
        "    labels[:, :end_prompt_idx] = -100\n",
        "\n",
        "    return {\n",
        "        'input_ids': tokenized_full_prompt.input_ids.flatten(),\n",
        "        'labels': labels.flatten(),\n",
        "        'attention_mask': tokenized_full_prompt.attention_mask.flatten(),\n",
        "    }\n",
        "\n",
        "data = data[\"train\"].shuffle(seed=42).map(generate_and_tokenize_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XzBM0b1R9cFA",
        "outputId": "75196e72-d349-41cd-f60f-388c933f0850"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[9969, 7136, 26818, 50123, 1242, 10125, 326, 527, 7058, 45832, 517, 6260, 1, 6582, 273, 264, 19694, 650, 8641, 4016, 5436, 220, 16, 23, 71, 15, 15, 13, 11615, 29484, 2493, 388, 14789, 67903, 5397, 24901, 82357, 11, 14508, 16559, 15632, 963, 4914, 1187, 10613, 3134, 497, 264, 1257, 75266, 822, 12788, 4458, 346, 7774, 17950, 1315, 9753, 26451, 40099, 939, 64738, 1189, 6582, 273, 1788, 47801, 662, 44789, 4420, 497, 264, 2385, 12, 6712, 88996, 963, 13, 330, 6582, 273, 49490, 939, 50988, 65374, 409, 31018, 96395, 11, 4759, 834, 35631, 6368, 24901, 6218, 285, 11, 9870, 2778, 2111, 41525, 489, 16776, 497, 264, 9333, 36035, 4438, 51727, 11, 512, 521, 4942, 324, 20238, 11, 36439, 963, 1729, 50504, 8505, 53, 11, 13527, 58010, 3614, 3591, 51989, 36887, 88, 95972, 1315, 330, 75, 30669, 63274, 3263, 61193, 4438, 5651, 5623, 98138, 360, 963, 409, 330, 5970, 811, 3845, 2847, 963, 497, 15537, 308, 1587, 288, 27564, 360, 13700, 409, 330, 37, 1869, 64, 506, 372, 64573, 1, 1842, 4438, 489, 1754, 662, 625, 3885, 409, 330, 51, 459, 809, 52378, 497, 1187, 312, 482, 3845, 4627, 2832, 541, 54367, 264, 1585, 580, 42611, 822, 17098, 3784, 1187, 138938, 38623, 26451, 834, 348, 10965, 1315, 70651, 330, 25776, 3845, 7814, 383, 324, 497, 63060, 294, 22052, 56791, 33897, 1842, 18806, 922, 79620, 37756, 7906, 20481, 409, 12095, 1842, 3784, 326, 87666, 13842, 685, 13, 444, 963, 263, 645, 3539, 460, 1515, 1788, 308, 7888, 3784, 4929, 53894, 11, 40276, 1268, 409, 3240, 2200, 36807, 11, 512, 220, 16, 21, 84759, 220, 16, 24, 17, 23, 13, 330, 8747, 9625, 1788, 1615, 21241, 1842, 1187, 22475, 2372, 7491, 28225, 68, 497, 827, 1315, 12, 6712, 13, 52456, 281, 5011, 4942, 11, 51989, 36887, 88, 264, 64285, 963, 6866, 939, 69884, 416, 662, 43353, 517, 939, 10659, 137391, 1735, 11, 32570, 294, 92725, 2922, 351, 7888, 21572, 296, 1952, 810, 409, 5772, 1137, 7906, 330, 33, 51722, 1704, 1729, 512, 2014, 275, 1, 3784, 3240, 2200, 36807, 11, 43729, 3784, 12095, 7906, 330, 43, 5249, 1, 662, 220, 16, 24, 20, 15, 11, 38623, 26451, 3483, 1167, 51989, 36887, 88, 13, 422, 6, 453, 963, 2122, 2338, 662, 469, 15083, 550, 76587, 642, 3489, 8747, 9572, 12962, 324, 645, 1, 9753, 94259, 4570, 10302, 658, 1842, 38375, 45252, 11, 330, 3120, 64, 4914, 326, 57491, 413, 1, 9753, 33197, 2876, 13088, 11, 330, 9707, 422, 8618, 3975, 662, 1494, 517, 1346, 512, 435, 554, 11, 1187, 521, 36545, 11, 512, 75580, 8835, 10157, 11, 512, 143377, 1842, 3541, 42016, 65402, 11, 326, 6, 13573, 266, 343, 480, 8587, 2782, 16776, 19694, 855, 56023, 294, 22052, 38043, 77, 43518, 47744, 883, 685, 591, 13, 45308, 662, 6447, 24137, 811, 9333, 79, 10302, 5930, 11, 259, 3431, 13700, 11, 662, 53287, 54655, 409, 521, 596, 2382, 1842, 11968, 11981, 409, 143377, 11, 3784, 650, 33919, 339, 2660, 20792, 51885, 13, 18888, 326, 57491, 810, 810, 4808, 63729, 42889, 43667, 6185, 8250, 6817, 1160, 23120, 13, 133846, 38829, 64285, 963, 9753, 37337, 64, 479, 3083, 884, 3489, 21999, 24209, 86355, 296, 95187, 683, 963, 497, 220, 16, 24, 20, 18, 701, 26451, 264, 3958, 26897, 72, 1842, 3958, 15128, 4438, 584, 1346, 939, 435, 9574, 642, 13548, 266, 8303, 6866, 330, 2304, 9970, 1409, 409, 1187, 625, 84, 645, 1, 409, 13775, 963, 2435, 41525, 11, 330, 2304, 12853, 1, 320, 47, 44423, 26524, 1268, 12, 1912, 802, 265, 8, 5908, 330, 8747, 431, 7564, 552, 1, 320, 64117, 793, 910, 370, 1080, 568, 2925, 220, 17, 15, 16, 20, 11, 26451, 4438, 811, 16559, 27363, 69274, 6866, 4438, 137614, 409, 6662, 1448, 12068, 48084, 361, 810, 6866, 330, 23711, 5822, 1037, 16838, 1, 409, 19685, 9299, 4943, 28522, 586, 13, 71953, 326, 6, 93311, 409, 15537, 220, 24, 15, 8099, 662, 220, 17, 15, 16, 23, 11, 3240, 2200, 36807, 49490, 42624, 67968, 650, 44640, 3784, 4438, 9662, 13, 330, 34, 8294, 19694, 650, 66681, 3625, 3352, 480, 294, 92725, 43251, 312, 5148, 361, 1346, 3541, 4403, 724, 497, 49490, 7439, 12821, 963, 326, 6, 471, 16776, 3784, 326, 6, 46654, 11, 24901, 3958, 91138, 1346, 40967, 4998, 52310, 6866, 4438, 21241, 308, 4212, 624, 27, 77091, 26818, 4929, 521, 4942, 810, 1656, 709, 51989, 36887, 88, 11, 946, 649, 65422, 409, 93399, 31749, 17276, 21572, 330, 51, 459, 809, 52378, 1, 1842, 330, 8747, 50551, 3845, 2847, 963, 497, 1788, 34781, 15083, 7888, 18672, 64599, 3784, 326, 6, 8835, 709, 409, 220, 24, 17, 8099, 11, 3784, 78663, 4110, 285, 11, 83264, 409, 83520, 11, 264, 1257, 75266, 822, 12788, 4458, 346, 5271, 50353, 1967, 5970, 3784, 326, 6, 46654, 13, 151643]\n",
            "[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 4929, 521, 4942, 810, 1656, 709, 51989, 36887, 88, 11, 946, 649, 65422, 409, 93399, 31749, 17276, 21572, 330, 51, 459, 809, 52378, 1, 1842, 330, 8747, 50551, 3845, 2847, 963, 497, 1788, 34781, 15083, 7888, 18672, 64599, 3784, 326, 6, 8835, 709, 409, 220, 24, 17, 8099, 11, 3784, 78663, 4110, 285, 11, 83264, 409, 83520, 11, 264, 1257, 75266, 822, 12788, 4458, 346, 5271, 50353, 1967, 5970, 3784, 326, 6, 46654, 13, 151643]\n"
          ]
        }
      ],
      "source": [
        "print(data['input_ids'][10])\n",
        "print(data['labels'][10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGfbqJ_cNHDa"
      },
      "source": [
        "#### <b>Finetuning:</b>\n",
        "\n",
        "Since training samples vary in length, we use a data collator to handle batching. Specifically, we use `DataCollatorForSeq2Seq`, which:\n",
        "\n",
        "- Pads inputs and attention masks to the longest sequence in the batch.\n",
        "- Ensures that padding tokens in labels are set to `-100`, preventing the model from learning to predict padding.\n",
        "\n",
        "This approach allows us to efficiently train our model while ensuring it only learns to generate the assistant‚Äôs response, improving its completion capabilities.\n",
        "\n",
        "To fine-tune our model efficiently, we will use the Hugging Face Trainer, a high-level API that simplifies training and evaluation. The Trainer handles gradient accumulation, mixed-precision training, checkpointing, logging, and distributed training, making it ideal for large-scale fine-tuning.\n",
        "\n",
        "When configuring the Trainer, we define several key parameters in the TrainingArguments:\n",
        "\n",
        "- `per_device_train_batch_size`: Controls the number of samples processed per GPU per step. Smaller values (e.g., 2, 4) are used for memory efficiency.\n",
        "- `gradient_accumulation_steps`\n",
        "- `num_train_epochs`: Defines how many times the model sees the entire dataset during training (typically 2‚Äì3 epochs for fine-tuning).\n",
        "- `learning_rate`: Determines how much the model adjusts weights per step. A low learning rate (e.g., 2e-5) helps prevent catastrophic forgetting.\n",
        "- `lr_scheduler_type`: Controls how the learning rate decays over time (e.g., \"cosine\" or \"linear\" are commonly used).\n",
        "- `warmup_steps`: Defines the number of initial training steps with a reduced learning rate to stabilize training.\n",
        "- `logging_steps`: Specifies how often training metrics (e.g., loss) are logged.\n",
        "save_steps: Determines how frequently model checkpoints are saved.\n",
        "- `fp16` or `bf16`: Enables mixed-precision training to reduce memory usage and speed up training on compatible GPUs.\n",
        "- `push_to_hub`: Allows automatic saving and sharing of fine-tuned models on the Hugging Face Hub.\n",
        "\n",
        "Once the Trainer is set up, training starts with the `.train()` method, handling dataset shuffling, optimization, and checkpointing automatically. By fine-tuning efficiently with these parameters, we can adapt our model to generate high-quality responses while optimizing memory and compute resources.\n",
        "\n",
        "P.S. it is normal if you do not see loss decrease in this PoC. (Qwen is already optimized for English chatting), for sanity check, just see if the response gets better. You are also encourged to try another languages if the dataset exists on huggingface (you will get bonus points)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cc2CuzjJdxlm"
      },
      "source": [
        "<b><h4><font color='red'>\n",
        "<hr style=\"border:10px solid red\"> </hr>\n",
        "Question 4: </b><br>\n",
        "What is the importance of gradient_accumulation_steps? and what is the role of DataCollatorForSeq2Seq?\n",
        "<hr style=\"border:10px solid red\"> </hr>\n",
        "</font></h4>\n",
        "\n",
        "<b><h4><font color='green'>\n",
        "<hr style=\"border:10px solid red\"> </hr>\n",
        "Answer 4: </b><br>\n",
        "\n",
        "The accumulation steps parameter allows gradients to be accumulated over multiple iterations before updating the model weights.\n",
        "This means simulating a larger overall batch without increasing the size of the batch processed by the GPU at each step.\n",
        "This is very useful when GPU memory is limited: it allows for the stability of a large batch while maintaining reduced memory consumption.\n",
        "\n",
        "The DataCollatorForSeq2Seq is used to prepare batches before they are sent to the model.\n",
        "It automatically takes care of:\n",
        "- padding sequences to the same length within a batch (by applying tupadding),\n",
        "- creating the corresponding attention masks,\n",
        "- and replacing the padding tokens in the labels with -100, so that the model does not consider them in the loss function.\n",
        "\n",
        "<hr style=\"border:10px solid red\"> </hr>\n",
        "</font></h4>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "sjBMVb6yW_74",
        "outputId": "91cdbfab-1a28-49a2-dfa3-ab0c2c04cd1c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [200/200 1:03:59, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.956700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.879800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>1.899000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>1.855200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.842400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>1.851200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>1.776300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>1.759700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>1.746800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.823200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=200, training_loss=1.8390285110473632, metrics={'train_runtime': 3859.3129, 'train_samples_per_second': 0.829, 'train_steps_per_second': 0.052, 'total_flos': 5950719374462208.0, 'train_loss': 1.8390285110473632, 'epoch': 0.6429576049829214})"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import DataCollatorForSeq2Seq\n",
        "\n",
        "OUTPUT_DIR = \"experiments\"\n",
        "\n",
        "training_args = transformers.TrainingArguments(\n",
        "    per_device_train_batch_size=1,\n",
        "    gradient_accumulation_steps=16,\n",
        "    num_train_epochs=2,\n",
        "    learning_rate=5e-4,\n",
        "    bf16=True,\n",
        "    save_total_limit=3,\n",
        "    logging_steps=20,\n",
        "    output_dir=OUTPUT_DIR,\n",
        "    max_steps=200,   # try more steps if you can\n",
        "    optim=\"paged_adamw_8bit\",\n",
        "    lr_scheduler_type=\"cosine\",\n",
        "    warmup_ratio=0.01,\n",
        "    report_to=\"tensorboard\",\n",
        ")\n",
        "\n",
        "trainer = transformers.Trainer(\n",
        "    model=model,\n",
        "    train_dataset=data,\n",
        "    args=training_args,\n",
        "    data_collator=DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model),\n",
        ")\n",
        "\n",
        "model.config.use_cache = False\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B01QbSicXknK",
        "outputId": "8fce2e5a-c517-426e-d9a1-d0bb315c530b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UsageError: Line magic function `%tensorboard` not found.\n"
          ]
        }
      ],
      "source": [
        "# %load_ext tensorboard\n",
        "%tensorboard --logdir experiments/runs --port 6008"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxy9b1f4Nqpd"
      },
      "source": [
        "#### <b>Test the model after the finetuning (out-of-distribution prompt):<b>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCYynNlrXDhf",
        "outputId": "17e5782a-467d-408c-e8fe-d932253b9df9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<human>:What equipment do I need for rock climbing?\n",
            "<assistant>{} Rock climbing is a sport that requires a set of equipment to perform the activity. The equipment needed for rock climbing includes: a helmet, harness, climbing rope, climbing ladder, climbing blocks, climbing equipment, and climbing shoes.\n",
            "CPU times: user 6.08 s, sys: 536 ¬µs, total: 6.08 s\n",
            "Wall time: 6.71 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "device = \"cuda:0\"\n",
        "## uncomment if you didn't have enough time to train\n",
        "# model = AutoModelForCausalLM.from_pretrained(\n",
        "#                     MODEL_NAME,\n",
        "#                     device_map=\"auto\",\n",
        "#                     trust_remote_code=True,\n",
        "#                     quantization_config=bnb_config,\n",
        "#                 )\n",
        "# model = PeftModelForCausalLM.from_pretrained(model, \"habdine/CSC_53432_lab2\")\n",
        "\n",
        "encoding = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "with torch.inference_mode():\n",
        "    outputs = model.generate(\n",
        "        input_ids=encoding.input_ids,\n",
        "        attention_mask=encoding.attention_mask,\n",
        "        generation_config=generation_config,\n",
        "    )\n",
        "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uH6e-HsOWXtk"
      },
      "source": [
        "<b><h4><font color='blue'>\n",
        "<hr style=\"border:10px solid blue\"> </hr>\n",
        "Task 5: </b><br>\n",
        "Fill the gaps to: (1) transform the data into prompts using the defined chat template. (2) extract only the response from the model's generated output.\n",
        "<hr style=\"border:10px solid blue\"> </hr>\n",
        "</font></h4>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "CS_lwrJdXr-Y"
      },
      "outputs": [],
      "source": [
        "def generate_response(prompt: str) -> str:\n",
        "    prompt = f\"<human>: R√©sumez l‚Äôarticle suivant :\\n{prompt}\\n<assistant>:\" #construct the prompt with the chat template to test the model. (the instruction is already included in the prompt)\n",
        "    encoding = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "    with torch.inference_mode():\n",
        "        outputs = model.generate(\n",
        "            input_ids=encoding.input_ids,\n",
        "            attention_mask=encoding.attention_mask,\n",
        "            generation_config=generation_config,\n",
        "        )\n",
        "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    assistant_start = \"<assistant>:\"\n",
        "    response_start = response.find(assistant_start)\n",
        "    return response[response_start + len(assistant_start):].strip()## FILL THE GAP: extract and return only what is after <assistant>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYaO6H_hXsvG",
        "outputId": "ad8fdf01-2494-408f-ec1a-7aff64f0bffb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Le gouvernement veut mettre en place une directive europ√©enne sur la transparence salariale. Elle devra √™tre adopt√©e par la France en 2026.\n",
            "\n",
            "\n",
            "\n",
            "- Do you know the reasons as to why people love coffee so much? \n",
            "\n",
            "Coffee is a beverage that is enjoyed by millions of people around the world. It‚Äôs a drink that‚Äôs been enjoyed for centuries, and it‚Äôs no wonder that people love it so much. In this article, we‚Äôll explore some of the reasons why people love coffee so much.\n",
            "Coffee is a beverage that is enjoyed by millions of people around the world. It‚Äôs a drink that‚Äôs been enjoyed for centuries, and it‚Äôs no wonder that people love it so much.\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"R√©sumez l‚Äôarticle suivant:\n",
        "Une petite r√©volution se pr√©pare. D'ici au 7 juin 2026, la France doit transposer dans son droit national une directive europ√©enne sur la transparence salariale. Son objectif est de r√©duire les in√©galit√©s de salaire entre femmes et hommes. Selon l'Insee, en France, √† temps de travail √©gal, les femmes sont encore pay√©es 14% de moins que les hommes.\n",
        "\n",
        "'√Ä travail √©gal, r√©mun√©ration √©gale. Et pour parvenir √† l‚Äô√©galit√© de r√©mun√©ration, il faut de la transparence. Les femmes doivent savoir si leur employeur les traite de mani√®re √©quitable', avait d√©clar√© la pr√©sidente de la Commission europ√©enne Ursula von der Leyen au moment de la publication de cette directive. Et elle implique des changements significatifs pour les salari√©s et les entreprises.\n",
        "\n",
        "Le premier changement concerne la recherche d'emploi. Les entreprises devront informer les candidats en amont du premier entretien sur la fourchette de salaire envisag√©e pour le poste propos√©.\n",
        "\n",
        "Cela laisse deux options aux employeurs: soit ils affichent une fourchette de salaire directement sur l'offre d'emploi, soit ils la communiquent directement aux candidats qui ont envoy√© leur CV avant le premier entretien.\n",
        "\n",
        "La deuxi√®me obligation est certainement celle qui va le plus bousculer la vie en entreprise. √Ä partir de 2026, les salari√©s pourront poser des questions tr√®s pr√©cises sur les r√©mun√©rations de leurs coll√®gues. Dans le d√©tail, ils pourront demander et recevoir par √©crit des informations (ventil√©es par sexe) sur les salaires moyens de leurs coll√®gues qui effectuent \"un travail √©gal ou un travail de m√™me valeur'.\n",
        "\n",
        "Cette disposition 'vise √† garantir que les travailleurs puissent se comparer', y compris √† des coll√®gues de l'autre sexe, qui ont un poste √©quivalent. Cela permettra d'aider les salari√©s √† savoir o√π ils se positionnent. Mais toute la question sera de savoir comment ces cat√©gories seront d√©finies et √† quel point elles seront larges.\n",
        "\n",
        "La directive impose une r√©ponse 'circonstanci√©e' et l‚Äôobligation pour l‚Äôemployeur si une diff√©rence de r√©mun√©ration est constat√©e sans √™tre justifi√©e par des crit√®res objectifs non sexistes de \"rem√©dier\" √† la situation.\n",
        "\n",
        "Le salari√© pourra aussi demander des pr√©cisions sur les crit√®res d'√©volution salariale. Les informations devront √™tre communiqu√©es dans un \"d√©lai raisonnable\" et au maximum sous deux mois et le salari√© aura le droit de demander des informations compl√©mentaires.\n",
        "\"\"\"\n",
        "#print('-', article,'\\n\\n')\n",
        "print(generate_response(prompt))\n",
        "\n",
        "\n",
        "# test the model on out-of-distribution prompt 2 :\n",
        "prompt = \"Do you know the reasons as to why people love coffee so much?\"\n",
        "print('\\n\\n\\n-', prompt, '\\n')\n",
        "print(generate_response(prompt))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "grNSwmt1omZ1"
      },
      "source": [
        "#### **Merging the main model with the adapter**\n",
        "\n",
        "After completing the fine-tuning process, our model consists of the original pre-trained weights and the LoRA adapters. Since LoRA fine-tunes only a small subset of parameters, the final step is to merge these adapters with the base model to create a fully fine-tuned version without dependency on PEFT. This is especially useful for deployment, as it removes the need for external adapters and improves inference efficiency.\n",
        "\n",
        "To merge the LoRA weights, we use the `merge_and_unload()` method from PEFT, which integrates the trained LoRA layers into the base model. Once merged, the model behaves as if it was fully fine-tuned, and we can save it for direct use without requiring PEFT or LoRA during inference."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z1bo54C4pZMW",
        "outputId": "d532dd97-9604-4875-dc95-1d72bedbfb22"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PeftModelForCausalLM(\n",
              "  (base_model): LoraModel(\n",
              "    (model): Qwen2ForCausalLM(\n",
              "      (model): Qwen2Model(\n",
              "        (embed_tokens): Embedding(151936, 896)\n",
              "        (layers): ModuleList(\n",
              "          (0-23): 24 x Qwen2DecoderLayer(\n",
              "            (self_attn): Qwen2Attention(\n",
              "              (q_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=896, out_features=896, bias=True)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=896, out_features=32, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=32, out_features=896, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (k_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=896, out_features=128, bias=True)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=896, out_features=32, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=32, out_features=128, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (v_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=896, out_features=128, bias=True)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=896, out_features=32, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=32, out_features=128, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (o_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=896, out_features=896, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=896, out_features=32, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=32, out_features=896, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "            )\n",
              "            (mlp): Qwen2MLP(\n",
              "              (gate_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=896, out_features=4864, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=896, out_features=32, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=32, out_features=4864, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (up_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=896, out_features=4864, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=896, out_features=32, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=32, out_features=4864, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (down_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=4864, out_features=896, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4864, out_features=32, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=32, out_features=896, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (act_fn): SiLUActivation()\n",
              "            )\n",
              "            (input_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
              "            (post_attention_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
              "          )\n",
              "        )\n",
              "        (norm): Qwen2RMSNorm((896,), eps=1e-06)\n",
              "        (rotary_emb): Qwen2RotaryEmbedding()\n",
              "      )\n",
              "      (lm_head): Linear(in_features=896, out_features=151936, bias=False)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model # check the model architecture with the added LoRA layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dd5WZDWdoylU",
        "outputId": "4da25df9-8825-4f56-bd43-5a37db40948e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/peft/tuners/lora/bnb.py:348: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "model = model.merge_and_unload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STgUbrVspb5P",
        "outputId": "51909e9d-552a-40ab-d3f9-aee52e7c8bd9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Qwen2ForCausalLM(\n",
              "  (model): Qwen2Model(\n",
              "    (embed_tokens): Embedding(151936, 896)\n",
              "    (layers): ModuleList(\n",
              "      (0-23): 24 x Qwen2DecoderLayer(\n",
              "        (self_attn): Qwen2Attention(\n",
              "          (q_proj): Linear4bit(in_features=896, out_features=896, bias=True)\n",
              "          (k_proj): Linear4bit(in_features=896, out_features=128, bias=True)\n",
              "          (v_proj): Linear4bit(in_features=896, out_features=128, bias=True)\n",
              "          (o_proj): Linear4bit(in_features=896, out_features=896, bias=False)\n",
              "        )\n",
              "        (mlp): Qwen2MLP(\n",
              "          (gate_proj): Linear4bit(in_features=896, out_features=4864, bias=False)\n",
              "          (up_proj): Linear4bit(in_features=896, out_features=4864, bias=False)\n",
              "          (down_proj): Linear4bit(in_features=4864, out_features=896, bias=False)\n",
              "          (act_fn): SiLUActivation()\n",
              "        )\n",
              "        (input_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
              "        (post_attention_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
              "      )\n",
              "    )\n",
              "    (norm): Qwen2RMSNorm((896,), eps=1e-06)\n",
              "    (rotary_emb): Qwen2RotaryEmbedding()\n",
              "  )\n",
              "  (lm_head): Linear(in_features=896, out_features=151936, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model # check the model architecture after merging."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8d4gN4tTu47d"
      },
      "source": [
        "To go further:\n",
        "- Check **VLLM** for fast batch inference.\n",
        "- Check **DDP**, **FSDP** and **Deepspeed** for distributed training with Hugging Face transformers.\n",
        "- Check **unsloth** for faster training.\n",
        "- Check **ollama** for chatting interface.\n",
        "- Test **multi-turn** and **few-shot learning**.\n",
        "- Check **Megatron, Nanotron, etc..** for distributed **pre-training** on big clusters.\n",
        "- Check **LLama Factory** (https://github.com/hiyouga/LLaMA-Factory) for **Finetuning**."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.20"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "00390ef4c2ae47d2a2e0aeadd243c4e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5529703f5e8b42829a04eafa5d7f489d",
            "max": 138,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_26f512f281154bc2a671ca9032f62140",
            "value": 138
          }
        },
        "016dc246900d4f82ac6b1d0ebeafad4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2846c5147b0644849581f420e1817772",
              "IPY_MODEL_ff6fa0aee5ea4454a179f6c3c14f9fc3",
              "IPY_MODEL_d2a0cf4017504bfa94c4e358fed13c66"
            ],
            "layout": "IPY_MODEL_5aa873d821a843589fd502122a2ef2b7"
          }
        },
        "02693d08230f40afaad5b517dcea156b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5309323cac39409ab0afd7a3f21abc91",
              "IPY_MODEL_c6abf84705b6472aafeadfd22241c2c8",
              "IPY_MODEL_2e5d4dbf42cd4acb930fc1b2ceeb8635"
            ],
            "layout": "IPY_MODEL_0d22c3713d8944369ee750181a1688a9"
          }
        },
        "03e11d0567f347da939219d7fbe7bd2a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07c1102d4abb49c7be8d0b71d39ae0ad": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "096cebe373e5443f88adb19ac1917a96": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a55c25909fb4ffcba918aae23062a2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b6bf2c7d8813479dafcfbcd6235a2eee",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_f17bba977fb64d8887960c651cf6cde6",
            "value": "‚Äá7.03M/?‚Äá[00:00&lt;00:00,‚Äá58.5MB/s]"
          }
        },
        "0b7886db752749c897cccaffb61a4fe5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0d22c3713d8944369ee750181a1688a9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "111721b2039b4d1a9eef2b600bd51e62": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e27b3439aa58443e8c26f9066deb5544",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_d1326ca9a28a4897b6eea25fdb5ee628",
            "value": "generation_config.json:‚Äá100%"
          }
        },
        "12be7a84871e422d93e8ce9163f14bf6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18c476442f654d46944028bcb6dea1f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "18d7e30e6e86421c8947869ce8ed58e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1b2b457922044fe095930e8970313e23": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb2578e9d5504032bb798220db6934d9",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_da62ac3e6dee4086ac6c36b0ce623e0d",
            "value": "‚Äá7.23k/?‚Äá[00:00&lt;00:00,‚Äá696kB/s]"
          }
        },
        "1ea233a13ae24852889b88dda54ed8cf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21123b76fb4545729c678f1b6e0f3aa3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ea233a13ae24852889b88dda54ed8cf",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_ad03c3f15c3143429208388a757930e8",
            "value": "model.safetensors:‚Äá100%"
          }
        },
        "26f512f281154bc2a671ca9032f62140": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "27b9e0408202451b9fa953b98f37fc19": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2846c5147b0644849581f420e1817772": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b50ee2a66fa94f42aa6e5c73c700146e",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_18d7e30e6e86421c8947869ce8ed58e9",
            "value": "config.json:‚Äá100%"
          }
        },
        "2af02b47c4454816bbe39923cb23a713": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03e11d0567f347da939219d7fbe7bd2a",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_47de712a122541819e0fdbc8d0bab144",
            "value": "‚Äá2.78M/?‚Äá[00:00&lt;00:00,‚Äá7.28MB/s]"
          }
        },
        "2c6b682a617e4121801716146cbcbd80": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_21123b76fb4545729c678f1b6e0f3aa3",
              "IPY_MODEL_6ff18712d3724cc6b261c4245fb535ca",
              "IPY_MODEL_6a5ef989a3b04c8bba7810e2caeaa776"
            ],
            "layout": "IPY_MODEL_c4964153ba2f40279af0a58a125ec649"
          }
        },
        "2e5d4dbf42cd4acb930fc1b2ceeb8635": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce539e8a90c143b087749213656d5c7d",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_a7923c0a6a9e4abf8a1a3d34108f83eb",
            "value": "‚Äá1.67M/?‚Äá[00:00&lt;00:00,‚Äá31.2MB/s]"
          }
        },
        "3ee5d686ed5d4e9f95aafdff3306724b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44d9f880d4df42b9a8c2970ce2fbe06e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "457945646c454fb2afe0036057ea2478": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47de712a122541819e0fdbc8d0bab144": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4905e59d4778472aad052fc927c48586": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6ce2a19a0eea455883971b4c6b5d368f",
              "IPY_MODEL_763350cc8eb94be8a9e04e2a44af888c",
              "IPY_MODEL_54d88cb95cf541c6b64dd69c5acc8c89"
            ],
            "layout": "IPY_MODEL_d359bb864887449b93f383ceebe5712c"
          }
        },
        "4bbd33200f2d4f70a3c9e82c6180ce5e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5309323cac39409ab0afd7a3f21abc91": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4bbd33200f2d4f70a3c9e82c6180ce5e",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_71e13f745b73412386ecaf77e1a3a7f4",
            "value": "merges.txt:‚Äá"
          }
        },
        "54d88cb95cf541c6b64dd69c5acc8c89": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c09a590b7a1949628e715b7b6ee9e82e",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_dedf8165fcf04241aa0b2e776b85f890",
            "value": "‚Äá5000/5000‚Äá[00:30&lt;00:00,‚Äá182.26‚Äáexamples/s]"
          }
        },
        "5529703f5e8b42829a04eafa5d7f489d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55bb76f0c1864f5cb73d564caf994b57": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5aa873d821a843589fd502122a2ef2b7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f8e1d2cefb144d2a50c56955a44cf0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5fe0e3ca26094887b8e2e2a51b8609af": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "68eab869c607401c8617e374229d9a7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "69aa6e90aa0a43c080a86757c1916786": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76c19a4b1e864f9da51923205f6a7e11",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f6216a395dc4485cbd4b8f3a54c84543",
            "value": 1
          }
        },
        "6a5ef989a3b04c8bba7810e2caeaa776": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_758eeb797856437aaca30fbe1379de5f",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_c3d4570f0230484eba3de3f899a1e9f2",
            "value": "‚Äá988M/988M‚Äá[00:24&lt;00:00,‚Äá45.6MB/s]"
          }
        },
        "6c06338aa2824c788b7b95d94d0ed0b5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "6ce2a19a0eea455883971b4c6b5d368f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27b9e0408202451b9fa953b98f37fc19",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_d3a374ce74264bd29ce4305394f510c3",
            "value": "Map:‚Äá100%"
          }
        },
        "6ff18712d3724cc6b261c4245fb535ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55bb76f0c1864f5cb73d564caf994b57",
            "max": 988097824,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c042d32a13464def96e23b0a291ed721",
            "value": 988097824
          }
        },
        "71e13f745b73412386ecaf77e1a3a7f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "758eeb797856437aaca30fbe1379de5f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "763350cc8eb94be8a9e04e2a44af888c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_096cebe373e5443f88adb19ac1917a96",
            "max": 5000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e9fd2d50cbbf4240b6a3e4663ae62098",
            "value": 5000
          }
        },
        "7652d83dfa4140479a4ab4129e746c92": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76c19a4b1e864f9da51923205f6a7e11": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "79bc7c86990a47f9962106b8c1c1bf04": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ee5d686ed5d4e9f95aafdff3306724b",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_7b280e3e10e54f289c127a0fcb7d6dba",
            "value": "tokenizer_config.json:‚Äá"
          }
        },
        "7b280e3e10e54f289c127a0fcb7d6dba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7cfade15caf0410c9af8395f10d654b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_79bc7c86990a47f9962106b8c1c1bf04",
              "IPY_MODEL_9cda1da37406458d89b792bc7abf7c2f",
              "IPY_MODEL_1b2b457922044fe095930e8970313e23"
            ],
            "layout": "IPY_MODEL_e62a7e318fbb4879b37373e54f79b44e"
          }
        },
        "81a347fd1cd34ff2931e95dcded7bab2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84efd3f32661479ea722cc20fd6d11c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b26a0fbc43c415b8563a1eab3a017ee",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_0b7886db752749c897cccaffb61a4fe5",
            "value": "vocab.json:‚Äá"
          }
        },
        "8553b312076a40d183a410d2f66a04d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c07186353f674b6ebc6a049116163776",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5f8e1d2cefb144d2a50c56955a44cf0b",
            "value": 1
          }
        },
        "8aa8f681889940c5ab78b70c43f36895": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8de04f39f6bc432cbafa1ca3b1735719": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_84efd3f32661479ea722cc20fd6d11c5",
              "IPY_MODEL_8553b312076a40d183a410d2f66a04d4",
              "IPY_MODEL_2af02b47c4454816bbe39923cb23a713"
            ],
            "layout": "IPY_MODEL_81a347fd1cd34ff2931e95dcded7bab2"
          }
        },
        "9b26a0fbc43c415b8563a1eab3a017ee": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9cda1da37406458d89b792bc7abf7c2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e903d036c0954d37b17fe1aa77bebf4b",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_18c476442f654d46944028bcb6dea1f1",
            "value": 1
          }
        },
        "a642d4cc1b004bbba23c3c607a832b0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e3455db1655d4f0c9f80bfa38955e59d",
              "IPY_MODEL_69aa6e90aa0a43c080a86757c1916786",
              "IPY_MODEL_0a55c25909fb4ffcba918aae23062a2e"
            ],
            "layout": "IPY_MODEL_af7e08e9bed0464797c94b1355478727"
          }
        },
        "a7923c0a6a9e4abf8a1a3d34108f83eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ad03c3f15c3143429208388a757930e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "af7e08e9bed0464797c94b1355478727": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b50ee2a66fa94f42aa6e5c73c700146e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6bf2c7d8813479dafcfbcd6235a2eee": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c042d32a13464def96e23b0a291ed721": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c07186353f674b6ebc6a049116163776": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "c09a590b7a1949628e715b7b6ee9e82e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3d4570f0230484eba3de3f899a1e9f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c4964153ba2f40279af0a58a125ec649": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6abf84705b6472aafeadfd22241c2c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c06338aa2824c788b7b95d94d0ed0b5",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8aa8f681889940c5ab78b70c43f36895",
            "value": 1
          }
        },
        "ce539e8a90c143b087749213656d5c7d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1326ca9a28a4897b6eea25fdb5ee628": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d2a0cf4017504bfa94c4e358fed13c66": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_457945646c454fb2afe0036057ea2478",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_68eab869c607401c8617e374229d9a7c",
            "value": "‚Äá681/681‚Äá[00:00&lt;00:00,‚Äá85.5kB/s]"
          }
        },
        "d344cf337973452aae91223f5ab2e30c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ded8613d89d44362835bbf1e5ab2f9be",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_44d9f880d4df42b9a8c2970ce2fbe06e",
            "value": "‚Äá138/138‚Äá[00:00&lt;00:00,‚Äá9.14kB/s]"
          }
        },
        "d359bb864887449b93f383ceebe5712c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3a374ce74264bd29ce4305394f510c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "da62ac3e6dee4086ac6c36b0ce623e0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dbd126a69b2a495fb267e3591942cb64": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ded8613d89d44362835bbf1e5ab2f9be": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dedf8165fcf04241aa0b2e776b85f890": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e27b3439aa58443e8c26f9066deb5544": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3455db1655d4f0c9f80bfa38955e59d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7652d83dfa4140479a4ab4129e746c92",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_dbd126a69b2a495fb267e3591942cb64",
            "value": "tokenizer.json:‚Äá"
          }
        },
        "e62a7e318fbb4879b37373e54f79b44e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6387a5f695445a98c8995cecbf18435": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_111721b2039b4d1a9eef2b600bd51e62",
              "IPY_MODEL_00390ef4c2ae47d2a2e0aeadd243c4e8",
              "IPY_MODEL_d344cf337973452aae91223f5ab2e30c"
            ],
            "layout": "IPY_MODEL_07c1102d4abb49c7be8d0b71d39ae0ad"
          }
        },
        "e903d036c0954d37b17fe1aa77bebf4b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "e9fd2d50cbbf4240b6a3e4663ae62098": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eb2578e9d5504032bb798220db6934d9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f17bba977fb64d8887960c651cf6cde6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f6216a395dc4485cbd4b8f3a54c84543": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ff6fa0aee5ea4454a179f6c3c14f9fc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12be7a84871e422d93e8ce9163f14bf6",
            "max": 681,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5fe0e3ca26094887b8e2e2a51b8609af",
            "value": 681
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
